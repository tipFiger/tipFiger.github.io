---
layout: post
title: "KNN算法"
date: 2016-06-11 13:20:08 
description: "KNN算法基础学习"
tag: 机器学习算法模型
---

### KNN算法基础总结

> 生命中总有那么一段时光，充满不安，可是除了勇敢面对，我们别无选择。

作为入门级算法，k近邻还是比较友好的，核心就是对于距离的计算（欧式距离）。

**算法原理**

```
    存在一个每个数据都有标签的样本集（即我们知道样本集中每一数据与所属分类对应的关系），输入待分类样本集，将新数据中的每个特征与样本集中数据对应的特征进行比较，提取出样本集中特征最相似数据（最近邻）的分类标签。
```

**算法流程**

```
1. 计算测试数据与各个训练数据之间的距离；
2. 按照距离的递增关系进行排序；
3. 选取距离最小的K个点；
4. 确定前K个点所在类别的出现频率；
5. 返回前K个点中出现频率最高的类别作为测试数据的预测分类。
下图中给出了KNN算法中K值选区的规则：
```

**算法优缺点**

```
优点：简单，易于理解，无需建模与训练，易于实现；适合对稀有事件进行分类；适合与多分类问题，例如根据基因特征来判断其功能分类，kNN比SVM的表现要好。
缺点：惰性算法，内存开销大，对测试样本分类时计算量大，性能较低；可解释性差，无法给出决策树那样的规则。
```

**算法问题与解决**

```
1、当样本不平衡时，比如一个类的样本容量很大，其他类的样本容量很小，输入一个样本的时候，K个临近值中大多数都是大样本容量的那个类，这时可能就会导致分类错误。改进方法是对K临近点进行加权，也就是距离近的点的权值大，距离远的点权值小。 
2、计算量较大，每个待分类的样本都要计算它到全部点的距离，根据距离排序才能求得K个临近点，改进方法是：先对已知样本点进行剪辑，事先去除对分类作用不大的样本。
```

**算法数学原理之欧式距离**

```
最常见的两点之间或多点之间的距离表示法，又称之为欧几里得度量，它定义于欧几里得空间中，如点 x = (x1,...,xn) 和 y = (y1,...,yn) 之间的距离为：
```

![1562690804115](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1562690804115.png)

```python
 1 import numpy as np
 2 from scipy.spatial.distance import pdist
 3 from numpy import *
 4 # 欧几里得距离
 5 def oljdDistance():
 6     vec1 = np.mat([1,2,3,4])
 7     vec2 = np.mat([5,6,7,8])
 8 
 9     print("vec1 = ",vec1)
10     print("vec2 = ",vec2)
11 
12     #方法一 公式求解
13     dist1 = np.sqrt(np.sum(np.square(vec1 - vec2)))
14     print("欧氏距离测试的结果为 dist1 = "+str(dist1))
15 
16     #方法二 根据scipy库求解
17     Vec = np.vstack([vec1,vec2])
18     dist2 = pdist(Vec)
19     print("欧氏距离测试的结果为 dist2 = "+str(dist2))
20 
21     #方法三 根据公式求解
22     dist3 = sqrt((vec1 - vec2) * (vec1 - vec2).T)
23     print("欧氏距离测试的结果为 dist3 = "+str(dist3))
```

**k近邻计算过程图**

![1562691018786](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1562691018786.png)

<br>

转载请注明：[点墨的博客](http://tipFiger.github.io) » [点击阅读原文](http://tipFiger.github.io/2018/07/KNN算法/)

